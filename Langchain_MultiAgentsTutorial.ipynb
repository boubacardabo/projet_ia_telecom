{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain supports a restricted list of opensource models. I used code llama in this case, which was one of the only models that did not ask for a meta key AND was usable without running on a GPU. We first install the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (23.3.1)\n",
      "Requirement already satisfied: auto-gptq in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: accelerate>=0.19.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from auto-gptq) (0.24.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from auto-gptq) (2.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from auto-gptq) (1.26.2)\n",
      "Requirement already satisfied: rouge in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from auto-gptq) (1.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from auto-gptq) (2.1.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from auto-gptq) (0.4.1)\n",
      "Requirement already satisfied: transformers>=4.29.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from auto-gptq) (4.35.2)\n",
      "Requirement already satisfied: peft in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from auto-gptq) (0.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from accelerate>=0.19.0->auto-gptq) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from accelerate>=0.19.0->auto-gptq) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from accelerate>=0.19.0->auto-gptq) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from accelerate>=0.19.0->auto-gptq) (0.19.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.13.0->auto-gptq) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.13.0->auto-gptq) (2023.10.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from transformers>=4.29.0->auto-gptq) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from transformers>=4.29.0->auto-gptq) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from transformers>=4.29.0->auto-gptq) (0.15.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from transformers>=4.29.0->auto-gptq) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->auto-gptq) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->auto-gptq) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->auto-gptq) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->auto-gptq) (2.1.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->auto-gptq) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->auto-gptq) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->auto-gptq) (3.9.1)\n",
      "Requirement already satisfied: six in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from rouge->auto-gptq) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->transformers>=4.29.0->auto-gptq) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->transformers>=4.29.0->auto-gptq) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->transformers>=4.29.0->auto-gptq) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->transformers>=4.29.0->auto-gptq) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from tqdm>=4.27->transformers>=4.29.0->auto-gptq) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from pandas->datasets->auto-gptq) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from accelerate) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from accelerate) (2.1.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from accelerate) (0.19.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Collecting optimum\n",
      "  Downloading optimum-1.14.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting coloredlogs (from optimum)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: sympy in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from optimum) (1.12)\n",
      "Requirement already satisfied: transformers>=4.26.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (4.35.2)\n",
      "Requirement already satisfied: torch>=1.9 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from optimum) (2.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from optimum) (23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from optimum) (1.26.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from optimum) (0.19.4)\n",
      "Requirement already satisfied: datasets in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from optimum) (2.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from huggingface-hub>=0.8.0->optimum) (4.8.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.9->optimum) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from torch>=1.9->optimum) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum) (0.4.1)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]>=4.26.0->optimum)\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "     ---------------------------------------- 0.0/977.5 kB ? eta -:--:--\n",
      "     ------- ------------------------------ 204.8/977.5 kB 6.3 MB/s eta 0:00:01\n",
      "     -------------------- ----------------- 522.2/977.5 kB 6.6 MB/s eta 0:00:01\n",
      "     ----------------------- -------------- 614.4/977.5 kB 6.4 MB/s eta 0:00:01\n",
      "     ----------------------------- -------- 768.0/977.5 kB 4.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 977.5/977.5 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting protobuf (from transformers[sentencepiece]>=4.26.0->optimum)\n",
      "  Downloading protobuf-4.25.1-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 86.8/86.8 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->optimum) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->optimum) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->optimum) (0.3.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->optimum) (2.1.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->optimum) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->optimum) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from datasets->optimum) (3.9.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from aiohttp->datasets->optimum) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from aiohttp->datasets->optimum) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from aiohttp->datasets->optimum) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from aiohttp->datasets->optimum) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->optimum)\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 0.0/95.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 95.2/95.2 kB 5.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.8.0->optimum) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from jinja2->torch>=1.9->optimum) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from pandas->datasets->optimum) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from pandas->datasets->optimum) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from pandas->datasets->optimum) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yokor\\onedrive\\documents\\mistraltests\\langchainagents\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n",
      "Downloading optimum-1.14.1-py3-none-any.whl (399 kB)\n",
      "   ---------------------------------------- 0.0/399.9 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 235.5/399.9 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 399.9/399.9 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.1-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 286.7/413.4 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 413.4/413.4 kB 5.2 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece, pyreadline3, protobuf, humanfriendly, coloredlogs, optimum\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 optimum-1.14.1 protobuf-4.25.1 pyreadline3-3.4.1 sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install auto-gptq\n",
    "!{sys.executable} -m pip install accelerate\n",
    "!{sys.executable} -m pip install optimum\n",
    "!{sys.executable} -m pip install transformers\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 180355072 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yokor\\OneDrive\\Documents\\mistralTests\\Langchain_MultiAgentsTutorial.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yokor/OneDrive/Documents/mistralTests/Langchain_MultiAgentsTutorial.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#torch.FloatTensor(1).to('cuda')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yokor/OneDrive/Documents/mistralTests/Langchain_MultiAgentsTutorial.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(MODEL_NAME, use_fast\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yokor/OneDrive/Documents/mistralTests/Langchain_MultiAgentsTutorial.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yokor/OneDrive/Documents/mistralTests/Langchain_MultiAgentsTutorial.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     MODEL_NAME\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yokor/OneDrive/Documents/mistralTests/Langchain_MultiAgentsTutorial.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yokor/OneDrive/Documents/mistralTests/Langchain_MultiAgentsTutorial.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m generation_config \u001b[39m=\u001b[39m GenerationConfig\u001b[39m.\u001b[39mfrom_pretrained(MODEL_NAME)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yokor/OneDrive/Documents/mistralTests/Langchain_MultiAgentsTutorial.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m generation_config\u001b[39m.\u001b[39mmax_new_tokens \u001b[39m=\u001b[39m \u001b[39m1024\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\yokor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    565\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 566\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[0;32m    567\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    568\u001b[0m     )\n\u001b[0;32m    569\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yokor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:3236\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3233\u001b[0m     config \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_check_and_enable_flash_attn_2(config, torch_dtype\u001b[39m=\u001b[39mtorch_dtype, device_map\u001b[39m=\u001b[39mdevice_map)\n\u001b[0;32m   3235\u001b[0m \u001b[39mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m-> 3236\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(config, \u001b[39m*\u001b[39;49mmodel_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[0;32m   3238\u001b[0m \u001b[39m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[0;32m   3239\u001b[0m config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n",
      "File \u001b[1;32mc:\\Users\\yokor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:961\u001b[0m, in \u001b[0;36mLlamaForCausalLM.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config):\n\u001b[0;32m    960\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(config)\n\u001b[1;32m--> 961\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m LlamaModel(config)\n\u001b[0;32m    962\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_size \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mvocab_size\n\u001b[0;32m    963\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(config\u001b[39m.\u001b[39mhidden_size, config\u001b[39m.\u001b[39mvocab_size, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\yokor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:823\u001b[0m, in \u001b[0;36mLlamaModel.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_size \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mvocab_size\n\u001b[0;32m    822\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(config\u001b[39m.\u001b[39mvocab_size, config\u001b[39m.\u001b[39mhidden_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_idx)\n\u001b[1;32m--> 823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([LlamaDecoderLayer(config) \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(config\u001b[39m.\u001b[39;49mnum_hidden_layers)])\n\u001b[0;32m    824\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39m=\u001b[39m LlamaRMSNorm(config\u001b[39m.\u001b[39mhidden_size, eps\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mrms_norm_eps)\n\u001b[0;32m    826\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_checkpointing \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yokor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:823\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_size \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mvocab_size\n\u001b[0;32m    822\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(config\u001b[39m.\u001b[39mvocab_size, config\u001b[39m.\u001b[39mhidden_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_idx)\n\u001b[1;32m--> 823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([LlamaDecoderLayer(config) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config\u001b[39m.\u001b[39mnum_hidden_layers)])\n\u001b[0;32m    824\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39m=\u001b[39m LlamaRMSNorm(config\u001b[39m.\u001b[39mhidden_size, eps\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mrms_norm_eps)\n\u001b[0;32m    826\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_checkpointing \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yokor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:634\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mhidden_size\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn \u001b[39m=\u001b[39m (\n\u001b[0;32m    630\u001b[0m     LlamaAttention(config\u001b[39m=\u001b[39mconfig)\n\u001b[0;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39m_flash_attn_2_enabled\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    632\u001b[0m     \u001b[39melse\u001b[39;00m LlamaFlashAttention2(config\u001b[39m=\u001b[39mconfig)\n\u001b[0;32m    633\u001b[0m )\n\u001b[1;32m--> 634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp \u001b[39m=\u001b[39m LlamaMLP(config)\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layernorm \u001b[39m=\u001b[39m LlamaRMSNorm(config\u001b[39m.\u001b[39mhidden_size, eps\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mrms_norm_eps)\n\u001b[0;32m    636\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_attention_layernorm \u001b[39m=\u001b[39m LlamaRMSNorm(config\u001b[39m.\u001b[39mhidden_size, eps\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[1;32mc:\\Users\\yokor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:235\u001b[0m, in \u001b[0;36mLlamaMLP.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mhidden_size\n\u001b[0;32m    234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_size \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mintermediate_size\n\u001b[1;32m--> 235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgate_proj \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mLinear(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate_size, bias\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mup_proj \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_size, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    237\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_proj \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\yokor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features \u001b[39m=\u001b[39m in_features\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_features \u001b[39m=\u001b[39m out_features\n\u001b[1;32m---> 96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39;49mempty((out_features, in_features), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs))\n\u001b[0;32m     97\u001b[0m \u001b[39mif\u001b[39;00m bias:\n\u001b[0;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(out_features, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 180355072 bytes."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
    " \n",
    "MODEL_NAME = \"codellama/CodeLlama-7b-hf\"\n",
    "#MODEL_NAME = \"C:/Users/yokor/.cache/huggingface/hub/models--codellama--CodeLlama-7b-hf/snapshots/bc5283229e2fe411552f55c71657e97edf79066c\"\n",
    "#torch.FloatTensor(1).to('cuda')\n",
    "                        \n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    " \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME\n",
    ")\n",
    " \n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "generation_config.max_new_tokens = 1024\n",
    "generation_config.temperature = 0.0001\n",
    "generation_config.top_p = 0.95\n",
    "generation_config.do_sample = True\n",
    "generation_config.repetition_penalty = 1.15\n",
    " \n",
    "text_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    " \n",
    "llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0})\n",
    "llm.invoke(\"how many letters in the word educa?\") #this prompts the llm to give a response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to invoke tools from LangChain. These tools will be used by Agents automatically, which means that the models will help choose which tool is best suited for which task.\n",
    "We can also create new tools as shown right below; they are simply python functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En bas on peut voire comment définir un prompt qu'on associe à un agent. Le messageplaceholder donne un mot qui ne changent pas, ce qui permet de donner un nom à l'agent. https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/msg_prompt_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try using the tools provided by Langchain: You just need to bind them to our llm, so that they are used at the right time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now we can simply make an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we retry the same prompt as before:\n",
    "agent.invoke({\"input\": \"how many letters in the word educa?\", \"intermediate_steps\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a more complex example, we can reiterate over the same agent:\n",
    "from langchain.schema.agent import AgentFinish\n",
    "\n",
    "user_input = \"how many letters in the word educa?\"\n",
    "intermediate_steps = []\n",
    "while True:\n",
    "    output = agent.invoke(\n",
    "        {\n",
    "            \"input\": user_input,\n",
    "            \"intermediate_steps\": intermediate_steps,\n",
    "        }\n",
    "    )\n",
    "    if isinstance(output, AgentFinish):\n",
    "        final_result = output.return_values[\"output\"]\n",
    "        break\n",
    "    else:\n",
    "        print(f\"TOOL NAME: {output.tool}\")\n",
    "        print(f\"TOOL INPUT: {output.tool_input}\")\n",
    "        tool = {\"get_word_length\": get_word_length}[output.tool]\n",
    "        observation = tool.run(output.tool_input)\n",
    "        intermediate_steps.append((output, observation))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using AgentExecutor, we can have the same code with a simpler interface:\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"how many letters in the word educa?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we add some memory to make the self-conversation more meaningful:\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but bad at calculating lengths of words.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=MEMORY_KEY),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = \"how many letters in the word educa?\"\n",
    "result = agent_executor.invoke({\"input\": input1, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=input1),\n",
    "        AIMessage(content=result[\"output\"]),\n",
    "    ]\n",
    ")\n",
    "agent_executor.invoke({\"input\": \"is that a real word?\", \"chat_history\": chat_history})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
