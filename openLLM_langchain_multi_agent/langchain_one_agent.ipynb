{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenLLM\n",
    "\n",
    "server_url = \"http://0.0.0.0:8001\"  # Replace with remote host if you are running on a remote server\n",
    "llm = OpenLLM(server_url=server_url, max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timed out\n",
      "timed out\n",
      "timed out\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "<Request('POST', 'http://0.0.0.0:8001/v1/generate')>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/boubacardabo/Desktop/school/projet_ia_telecom/openLLM_langchain_multi_agent/langchain_one_agent.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/boubacardabo/Desktop/school/projet_ia_telecom/openLLM_langchain_multi_agent/langchain_one_agent.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mschema\u001b[39;00m \u001b[39mimport\u001b[39;00m HumanMessage\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/boubacardabo/Desktop/school/projet_ia_telecom/openLLM_langchain_multi_agent/langchain_one_agent.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhat would be a good company name for a company that makes colorful socks?Answer in one word only\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/boubacardabo/Desktop/school/projet_ia_telecom/openLLM_langchain_multi_agent/langchain_one_agent.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m result \u001b[39m=\u001b[39m llm\u001b[39m.\u001b[39;49minvoke(text)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/boubacardabo/Desktop/school/projet_ia_telecom/openLLM_langchain_multi_agent/langchain_one_agent.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m result\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/langchain/llms/base.py:229\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    220\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    221\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    226\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    227\u001b[0m     config \u001b[39m=\u001b[39m config \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    228\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 229\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    230\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    231\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    232\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    233\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    234\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    235\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    236\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    238\u001b[0m         \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    239\u001b[0m         \u001b[39m.\u001b[39mtext\n\u001b[1;32m    240\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/langchain/llms/base.py:507\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    500\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    501\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    505\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    506\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 507\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/langchain/llms/base.py:656\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    642\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m         )\n\u001b[1;32m    644\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    646\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    654\u001b[0m         )\n\u001b[1;32m    655\u001b[0m     ]\n\u001b[0;32m--> 656\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    657\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    658\u001b[0m     )\n\u001b[1;32m    659\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    660\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/langchain/llms/base.py:544\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    543\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 544\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    545\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    546\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/langchain/llms/base.py:531\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    522\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    523\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    528\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    529\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 531\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    532\u001b[0m                 prompts,\n\u001b[1;32m    533\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    534\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    535\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    536\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    537\u001b[0m             )\n\u001b[1;32m    538\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    539\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    540\u001b[0m         )\n\u001b[1;32m    541\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    542\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/langchain/llms/base.py:1053\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1050\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1051\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m   1052\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1053\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1054\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1055\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1056\u001b[0m     )\n\u001b[1;32m   1057\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[1;32m   1058\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/langchain/llms/openllm.py:275\u001b[0m, in \u001b[0;36mOpenLLM._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m config \u001b[39m=\u001b[39m openllm\u001b[39m.\u001b[39mAutoConfig\u001b[39m.\u001b[39mfor_model(\n\u001b[1;32m    272\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_identifying_params[\u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied\n\u001b[1;32m    273\u001b[0m )\n\u001b[1;32m    274\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client:\n\u001b[0;32m--> 275\u001b[0m     some \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    276\u001b[0m         prompt, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig\u001b[39m.\u001b[39;49mmodel_dump(flatten\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    277\u001b[0m     )\n\u001b[1;32m    278\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mres\u001b[39m\u001b[39m'\u001b[39m,some)\n\u001b[1;32m    279\u001b[0m     res \u001b[39m=\u001b[39m some\u001b[39m.\u001b[39mresponses[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/openllm_client/_http.py:83\u001b[0m, in \u001b[0;36mHTTPClient.generate\u001b[0;34m(self, prompt, llm_config, stop, adapter_name, timeout, verify, **attrs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m   llm_config \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mattrs}\n\u001b[0;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m     84\u001b[0m   \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_api_version\u001b[39m}\u001b[39;49;00m\u001b[39m/generate\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     85\u001b[0m   response_cls\u001b[39m=\u001b[39;49mResponse,\n\u001b[1;32m     86\u001b[0m   json\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(prompt\u001b[39m=\u001b[39;49mprompt, llm_config\u001b[39m=\u001b[39;49mllm_config, stop\u001b[39m=\u001b[39;49mstop, adapter_name\u001b[39m=\u001b[39;49madapter_name),\n\u001b[1;32m     87\u001b[0m   options\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mmax_retries\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_max_retries},\n\u001b[1;32m     88\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/openllm_client/_shim.py:478\u001b[0m, in \u001b[0;36mClient._post\u001b[0;34m(self, path, response_cls, json, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m options \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m   options \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 478\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    479\u001b[0m   response_cls, RequestOptions(method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m'\u001b[39;49m, url\u001b[39m=\u001b[39;49mpath, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions), stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls\n\u001b[1;32m    480\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/openllm_client/_shim.py:390\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, response_cls, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    382\u001b[0m   \u001b[39mself\u001b[39m,\n\u001b[1;32m    383\u001b[0m   response_cls: \u001b[39mtype\u001b[39m[Response],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m   stream_cls: \u001b[39mtype\u001b[39m[_Stream] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    389\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Response \u001b[39m|\u001b[39m _Stream:\n\u001b[0;32m--> 390\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    391\u001b[0m     response_cls\u001b[39m=\u001b[39;49mresponse_cls,\n\u001b[1;32m    392\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    393\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    394\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    395\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    396\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/openllm_client/_shim.py:423\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, response_cls, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException:\n\u001b[1;32m    422\u001b[0m   \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 423\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(response_cls, options, retries, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls)\n\u001b[1;32m    424\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(request) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# timeout\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/openllm_client/_shim.py:449\u001b[0m, in \u001b[0;36mClient._retry_request\u001b[0;34m(self, response_cls, options, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39m# In synchronous thread we are blocking the thread. Depends on how users want to do this downstream.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 449\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(response_cls, options, remaining, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls)\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/openllm_client/_shim.py:423\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, response_cls, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException:\n\u001b[1;32m    422\u001b[0m   \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 423\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(response_cls, options, retries, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls)\n\u001b[1;32m    424\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(request) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# timeout\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/openllm_client/_shim.py:449\u001b[0m, in \u001b[0;36mClient._retry_request\u001b[0;34m(self, response_cls, options, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39m# In synchronous thread we are blocking the thread. Depends on how users want to do this downstream.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 449\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(response_cls, options, remaining, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls)\n",
      "File \u001b[0;32m~/Desktop/school/projet_ia_telecom/nxp_venv/lib/python3.11/site-packages/openllm_client/_shim.py:424\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, response_cls, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    422\u001b[0m   \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    423\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry_request(response_cls, options, retries, stream\u001b[39m=\u001b[39mstream, stream_cls\u001b[39m=\u001b[39mstream_cls)\n\u001b[0;32m--> 424\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(request) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# timeout\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m   \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: <Request('POST', 'http://0.0.0.0:8001/v1/generate')>"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?Answer in one word only\"\n",
    "\n",
    "result = llm.invoke(text)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nxp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
